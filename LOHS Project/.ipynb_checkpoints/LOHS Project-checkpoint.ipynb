{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level of Heat Stress  Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "import xmltodict\n",
    "import fiona\n",
    "import os,os.path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import pymeanshift as pms\n",
    "import cv2\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "from io import BytesIO\n",
    "import math\n",
    "import scipy.misc\n",
    "from pvlib import solarposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining and selecting the routes latitude and longitude \n",
    "\n",
    "\n",
    "#Route1 = pd.read_excel('Route1.xlsx')\n",
    "#Route3 = pd.read_excel('Route3.xlsx')\n",
    "#Route4 = pd.read_excel('Route4.xlsx')\n",
    "#Route5 = pd.read_excel('Route5.xlsx')\n",
    "#frames = [Route1,Route2,Route3,Route4,Route5]\n",
    "#final_route= pd.concat(frames)\n",
    "#lat_list = list(final_route['Lat'])\n",
    "#long_list = list(final_route['Long'])\n",
    "\n",
    "\n",
    "#Select the specific routes containing Latitudes and Longitudes \n",
    "Route2 = pd.read_excel('Route2.xlsx')\n",
    "\n",
    "lat_list = list(Route2['Lat'])\n",
    "long_list = list(Route2['Long'])\n",
    "\n",
    "#Folder contains the Panorama Text Files.\n",
    "panaromaTextFolder = '../PanoramaTextFolder'\n",
    "if not os.path.exists(panaromaTextFolder):\n",
    "    os.makedirs(panaromaTextFolder)\n",
    "    \n",
    "#Folder contains Stitched Google Street View Images.\n",
    "GSVImages = '../GSV_Stiched_Images'\n",
    "if not os.path.exists(GSVImages):\n",
    "    os.makedirs(GSVImages)\n",
    "    \n",
    "#Folder contains Stitched Google Street View Images-Segnet.\n",
    "GSVImages_SEG = '../GSV_Stiched_Images_SEGNET'\n",
    "if not os.path.exists(GSVImages_SEG):\n",
    "    os.makedirs(GSVImages_SEG)\n",
    "\n",
    "\n",
    "#Temporary Folder containing the tile images from Google Street View.\n",
    "panaromaImageFolder= '../PanoramaImages'\n",
    "if not os.path.exists(panaromaImageFolder):\n",
    "    os.makedirs(panaromaImageFolder)\n",
    "      \n",
    "#Google Street View Images with Green Vew Factor Calculated\n",
    "GSV_GV= '../GSV_GV'\n",
    "if not os.path.exists(GSV_GV):\n",
    "    os.makedirs(GSV_GV)\n",
    "    \n",
    "#Google Street View Images with Sun Azimuth Angle Calculated\n",
    "GSVHemiSphere_Azimuth = '../GSV_Hemisphere_Azimuth'\n",
    "if not os.path.exists(GSVHemiSphere_Azimuth):\n",
    "    os.makedirs(GSVHemiSphere_Azimuth)\n",
    "    \n",
    "    \n",
    "panoDataFile = os.path.join(panaromaTextFolder,'PanoData.csv')\n",
    "panoInfoTextFile = os.path.join(panaromaTextFolder,'PanoInfoText.csv')\n",
    "greenViewTextFile = os.path.join(panaromaTextFolder,'GreenViewTextFile.csv')\n",
    "azimuthTextFile = os.path.join(panaromaTextFolder,'AzimuthFile.csv')\n",
    "pspNetSegTextFile = os.path.join(panaromaTextFolder,'PSPNET_Seg.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Panaroma of each and every Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadPanaromaForGoogleImages():\n",
    "    \n",
    "    with open(panoDataFile, 'w') as p_InfoText:\n",
    "        \n",
    "        i=0\n",
    "\n",
    "        for lat,lon in zip(lat_list,long_list):\n",
    "           \n",
    "            urlAddress = 'http://maps.google.com/cbk?output=xml&ll={0},{1}'.format(lat,lon)\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "            request = urllib.request.Request(urlAddress)\n",
    "            data = xmltodict.parse(urllib.request.urlopen(request).read())\n",
    "            \n",
    "            if i==0 :\n",
    "                lineTxt = '%s,%s,%s,%s\\n'%('panoID','panoDate','longitude','latitude')\n",
    "                p_InfoText.write(lineTxt)\n",
    "                i=i+1\n",
    "\n",
    "                \n",
    "            if data['panorama']==None:\n",
    "                continue\n",
    "            else:\n",
    "                p_Info = data['panorama']['data_properties']\n",
    "                p_Date = p_Info['@image_date']\n",
    "                p_Id = p_Info['@pano_id']\n",
    "                p_Lat = p_Info['@lat']\n",
    "                p_Lon = p_Info['@lng']\n",
    "                lineTxt = '%s,%s,%s,%s\\n'%(p_Id,p_Date,p_Lon,p_Lat)\n",
    "                p_InfoText.write(lineTxt)\n",
    "\n",
    "        p_InfoText.close()\n",
    "        df = pd.read_csv(panoDataFile, sep=\" \", header=None)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df.to_csv(panoInfoTextFile, header=None, index=None, sep=' ', mode='a')\n",
    "        print(\"Process Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadPanaromaForGoogleImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Stitch Together Google Street View Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlePanaromaTiles as panaromaTiles\n",
    "def downloadPanaromaImages():\n",
    "    lines = open(panoInfoTextFile,\"r\")\n",
    "    for i,line in enumerate(lines):  \n",
    "        if i==0:\n",
    "            continue\n",
    "        p_Data = line.split(\",\")\n",
    "        p_ID = p_Data[0]\n",
    "        p_Date = p_Data[1]\n",
    "        lon = p_Data[2]\n",
    "        lat = p_Data[3]\n",
    "    \n",
    "        #These are months where mostly the trees are green.\n",
    "        greenmonths = ['05','06','07','08','09']\n",
    "        month = p_Date.split(\"-\")[1]\n",
    "        if month not in greenmonths:\n",
    "            continue\n",
    "            \n",
    "        i_name =str(p_ID)\n",
    "        tiles= panaromaTiles.get_tiles(p_ID)\n",
    "        panaromaTiles.download_tiles(tiles,panaromaImageFolder)\n",
    "        panaromaTiles.stitch_images(p_ID,tiles,panaromaImageFolder,GSVImages,i_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadPanaromaImages()\n",
    "print(\"Process Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Green View Factor from the GSV Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import greenViewCalculator as gv_calc\n",
    "\n",
    "with open(greenViewTextFile,\"w\") as CSV_File:\n",
    "    i=0\n",
    "    for gsvfile in os.listdir(GSVImages):\n",
    "\n",
    "        gsvfilename = os.path.join(GSVImages,gsvfile)  \n",
    "        \n",
    "        if gsvfile == \".DS_Store\":\n",
    "            continue\n",
    "        panoID = gsvfile.split('.')[0]\n",
    "        \n",
    "        im = np.array(Image.open(gsvfilename))\n",
    "    \n",
    "        gv_image,greenPercent = gv_calc.greenViewClassification(im)\n",
    "        \n",
    "        cmap = plt.cm.jet\n",
    "        norm = plt.Normalize(vmin=gv_image.min(), vmax=gv_image.max())\n",
    "        image = cmap(norm(gv_image))\n",
    "\n",
    "        plt.imsave(GSV_GV + (\"/%s.jpg\" % panoID), image, cmap=cmap)\n",
    "        \n",
    "        if i==0:\n",
    "            i=i+1\n",
    "            lineTxt = '%s,%s\\n'%('panoID','greenViewValue')\n",
    "            CSV_File.write(lineTxt)\n",
    "        \n",
    "        lineTxt = '%s,%s\\n'%(panoID,greenPercent)\n",
    "        CSV_File.write(lineTxt)\n",
    "\n",
    "print(\"Process Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Azimuth Position and Angle of Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pano2hemisphere as hemishpere_img\n",
    "\n",
    "tz = 'EST'\n",
    "times = pd.date_range('2019-01-01 00:00:00', '2020-01-01', closed='left',\n",
    "                      freq='H', tz=tz)\n",
    "\n",
    "with open(azimuthTextFile,\"w\") as CSV_File:\n",
    "    for i, gsvfile in enumerate(os.listdir(GSVImages)):\n",
    "        elem = gsvfile.split(' - ')\n",
    "        if len(elem) < 3: continue\n",
    "        \n",
    "        gsvfilename = os.path.join(GSVImages,gsvfile)\n",
    "        panoID = elem[2]\n",
    "        lat = float(elem[0])\n",
    "        lon = float(elem[1])\n",
    "        panoDate = elem[-1][:-4]\n",
    "        solpos = solarposition.get_solarposition(times, lat, lon)\n",
    "        \n",
    "        # remove nighttime\n",
    "        solpos = solpos.loc[solpos['apparent_elevation'] > 0, :]\n",
    "        ax = plt.subplot(1, 1, 1, projection='polar')\n",
    "        # draw the analemma loops\n",
    "        \n",
    "        # draw hour labels\n",
    "        for hour in np.unique(solpos.index.hour):\n",
    "            # choose label position by the smallest radius for each hour\n",
    "            subset = solpos.loc[solpos.index.hour == hour, :]\n",
    "            r = subset.apparent_zenith\n",
    "            pos = solpos.loc[r.idxmin(), :]\n",
    "            ax.text(np.radians(pos['azimuth']), pos['apparent_zenith'], str(hour))\n",
    "        \n",
    "        date=panoDate+\"-1\"\n",
    "        for date in pd.to_datetime([date]):\n",
    "            times = pd.date_range(date, date+pd.Timedelta('24h'), freq='5min', tz=tz)\n",
    "            solpos = solarposition.get_solarposition(times, lat, lon)\n",
    "            solpos = solpos.loc[solpos['apparent_elevation'] > 0, :]\n",
    "            ax.plot(np.radians(solpos.azimuth), solpos.apparent_zenith, label=label)\n",
    "            \n",
    "        # change coordinates to be like a compass\n",
    "        ax.set_theta_zero_location('N')\n",
    "        ax.set_theta_direction(-1)\n",
    "        ax.set_rmax(90)\n",
    "    \n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='jpg', bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        im2 = Image.open(buf)\n",
    "        im2 = im2.resize((500, 500))\n",
    "\n",
    "        buf.close() # save the figure to file\n",
    "        ax.clear()\n",
    "        plt.close('all')\n",
    "\n",
    "        im1 = Image.open(gsvfilename)\n",
    "        hemi_image = hemishpere_img.pano2fisheye(im1)\n",
    "    \n",
    "     \n",
    "        blended = Image.blend(im2, hemi_image, alpha=0.5)\n",
    "        if i==0:\n",
    "            lineTxt = '%s\\n'%('panoID')\n",
    "            CSV_File.write(lineTxt)\n",
    "        \n",
    "        lineTxt = '%s\\n'%(panoID)\n",
    "        CSV_File.write(lineTxt)\n",
    "        \n",
    "        blended.save(GSVHemiSphere_Azimuth + (\"/%s.jpg\" % panoID))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
